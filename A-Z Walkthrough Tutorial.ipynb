{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial uses openAIs GPT models, hence an API key is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models & Model Wrappers: The Core of LangChain\n",
    "In LangChain, models are at the heart of the framework, enabling the integration and manipulation of large language models (LLMs) to fit specific application needs. Here, we explore how to initialize and use models with LangChain wrappers. These wrappers simplify the interaction with different LLMs, providing a unified interface to enhance usability and flexibility. We'll demonstrate using OpenAI's models as an example, illustrating both a standard LLM and Chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "\n",
    "# Initialize the standard LLM wrapper with the OpenAI API key.\n",
    "llm = OpenAI()\n",
    "\n",
    "# Initialize the Chat-oriented LLM wrapper with the OpenAI API key.\n",
    "chat_llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% chance of rain mean?\n",
      "\n",
      "A 10% chance of rain means that there is a 1 in 10 chance that it will rain in a specific area or location. This does not necessarily mean that it will rain for 10% of the day, but rather that there is a low likelihood of rain occurring at some point.\n"
     ]
    }
   ],
   "source": [
    "# Example of invoking the standard LLM with a prompt that's intentionally incomplete\n",
    "response = llm.invoke(\"ELI5: What does a \")\n",
    "# Normal LLMs like this simply predict and output the most likely next words following the given prompt.\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"phishing\" scam mean?\\n\\nImagine you receive an email or message from someone pretending to be a trusted company or person, like a bank or a friend. They ask you to click on a link or provide personal information like your password or credit card number. This is called phishing. The scammers are trying to trick you into giving them your sensitive information so they can steal from you or harm you in some way. It\\'s important to always be cautious and verify the legitimacy of any requests for personal information before responding.', response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 15, 'total_tokens': 119}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-3535e729-5b9b-46ae-afc2-75e44eeec271-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatBots, unlike standard LLMs, are designed to engage in conversations and provide answers. \n",
    "\n",
    "# Here we invoking the chat-oriented LLM with the same incomplete prompt\n",
    "response = chat_llm.invoke(\"ELI5: What does a \")\n",
    "\n",
    "# The `invoke()` function here does additional processing to handle the conversation dynamics, transforming your prompt into a 'HumanMessage' and responding with an 'AI Message'.\n",
    "# If correctly trained, the chatbot should respond with that it does not understand the question, as it is not fully formed. It does not always do that though xD\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "A prompt for a language model is a set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], template='This will be the prompt for my next call')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Let's create a simple prompt template. This is just a static string that we can use later to pass to an LLM.\n",
    "simple_prompt = PromptTemplate.from_template(\"This will be the prompt for my next call\")\n",
    "simple_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective', 'content'], template='Tell me a {adjective} joke about {content}.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# However, prompts can be dynamic too. Here, we define placeholders within the prompt that can be filled in later.\n",
    "# This makes it easy to customize the prompt without rewriting the whole thing each time.\n",
    "joke_prompt = PromptTemplate.from_template(\"Tell me a {adjective} joke about {content}.\")\n",
    "joke_prompt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can prompt an LLM simply by invoking the LLM with the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted prompt: This will be the prompt for my next call\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' to action\\n\\n\"Take action and make a difference! It\\'s time to use your voice and stand up for what you believe in. Whether it\\'s advocating for a cause, supporting a local charity, or volunteering in your community, your actions can have a positive impact. So don\\'t wait any longer, take action and be the change you want to see in the world!\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before using our simple prompt with the LLM, we need to format it to convert it from a template to a string.\n",
    "formatted_simple_prompt = simple_prompt.format()\n",
    "print(\"Formatted prompt:\", formatted_simple_prompt)  # Showing the formatted prompt.\n",
    "\n",
    "# Now we'll use this formatted prompt to ask our language model to generate a response.\n",
    "llm.invoke(formatted_simple_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted prompt: Tell me a funny joke about chickens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy did the chicken go to the seance?\\n\\nTo talk to the other side of the road!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formatting a prompt with variables. We provide values for the placeholders we defined earlier.\n",
    "formatted_joke_prompt = joke_prompt.format(adjective='funny', content='chickens')\n",
    "print(\"Formatted prompt:\", formatted_joke_prompt)  # Take a look at how the prompt looks now.\n",
    "\n",
    "# Let's see what kind of joke our LLM comes up with using this custom prompt.\n",
    "llm.invoke(formatted_joke_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains\n",
    "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step.\n",
    "\n",
    "With [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/expression_language/), we can _chain_ together operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy did the consultant cross the road?\\n\\nTo get to the middle management conference on the other side!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at how we can create a chain using LangChain. Here, we'll chain a prompt template with a chat-based LLM.\n",
    "chain = joke_prompt | chat_llm\n",
    "\n",
    "# Alternatively, you can use the 'pipe' method which explicitly shows the operation's flow from one component to the next.\n",
    "chain = joke_prompt.pipe(llm)\n",
    "\n",
    "# The '|' is known as the 'piping' operator, similar to Bash, where the output from the left operation serves as the input to the right operation.\n",
    "# This chaining effectively turns the process into a single callable sequence.\n",
    "\n",
    "# Now, let's invoke the chain. We need to provide the values for our prompt template's placeholders.\n",
    "chain.invoke({'adjective': 'cringy', 'content': 'consultant'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chains can be as complicated as you want them to be! They can involve processing runnables in parallel, include various tools and functions, and even integrate document retrieval capabilities and much more. This example is a basic introduction to get you started, but feel free to let your imagination and creativity take the lead in designing more complex workflows!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrievers\n",
    "Retrievers in LangChain are components designed to efficiently retrieve relevant documents or pieces of information from a larger corpus based on the input query. This capability is crucial for applications like question answering systems, where the model needs to access and understand specific information to generate accurate responses. The following example demonstrates how to set up a complete retrieval chain using various LangChain tools, from loading documents to querying them with a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith can help with testing by allowing developers to create datasets for running tests on LLM applications, uploading test cases in bulk, creating test cases on the fly, and exporting test cases from application traces. LangSmith also supports custom evaluations and provides a comparison view for tracking and diagnosing regressions in test scores across multiple revisions of an application. Additionally, LangSmith provides a playground environment for rapid iteration and experimentation, as well as the ability to capture feedback from users and attach feedback scores to logged traces for further analysis.\n"
     ]
    }
   ],
   "source": [
    "# First, we need some 'additional information' that can be retrieved.\n",
    "# For this, we will take the LangSmith user guide, which we can load in with beautifulsoup.\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Embeddings are used to convert text to a numerical format that a machine can understand.\n",
    "# Here we use the OpenAIEmbeddings module.\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# However, to use the embeddings, we need to split the document up into bite sized pieces that can be embedded.\n",
    "# For this, we can use a text splitter.\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# Now we can use the embeddings module and the splitted text to create a vector store.\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "\n",
    "# Alright, now we need a prompt that allows for the use of additional context.\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "# Next, we create a chain that integrates document processing with our chat model.\n",
    "# DOC: The input is a dictionary that must have a \"context\" key that maps to a List[Document], and any other input variables expected in the prompt. The Runnable return type depends on output_parser used.\n",
    "document_chain = create_stuff_documents_chain(chat_llm, prompt) # This is not the same as chaining! This us just a function! \n",
    "\n",
    "# The retriever is set up to fetch relevant documents based on the query.\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# Invoking the retrieval chain with a specific question to see how the system processes and retrieves relevant information.\n",
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "\n",
    "# To recap what this does:\n",
    "# We input a question in string format\n",
    "# FAISS does a similarity search to retrieve documents from the vector store and adds them to the 'context' variable. https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html\n",
    "# The context is fed to the prompt, which is formatted, and fed to the LLM, which generates a nice output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents (& Tools, and Parsers)\n",
    "Agents in LangChain represent a dynamic approach to handling sequences of actions. Unlike chains, where a sequence of actions is explicitly defined in the code, agents utilize a language model as a reasoning engine to dynamically determine the sequence and type of actions to execute based on context. This flexibility allows agents to adapt to changing inputs and complex decision-making scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "INPUT: {'topic1': 'singing', 'topic2': 'skiing', 'intermediate_steps': []}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `singing`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Singing\n",
      "Summary: Singing is the act of creating musical sounds with the voice. A person whose profession is singing is called a singer, artist or vocalist (in jazz and/or popular music). Singers perform music (arias, recitatives, songs, etc.) that can be sung with or without accompaniment by musical instruments. Singing is often done in an ensemble of musicians, such as a choir. Singers may perform as soloists or accompanied by anything from a single instrument (as in art songs or some jazz styles) up to a symphony orchestra or big band. Different singing styles include art music such as opera and Chinese opera, Indian music, Greek music, Japanese music, and religious music styles such as gospel, traditional music styles, world music, jazz, blues, ghazal, and popular music styles such as pop, rock, and electronic dance music.\n",
      "Singing can be formal or informal, arranged, or improvised. It may be done as a form of religious devotion, as a hobby, as a source of pleasure, comfort, as part of a ritual, during music education or as a profession. Excellence in singing requires time, dedication, instruction, and regular practice. If practice is done regularly then the sounds can become clearer and stronger. Professional singers usually build their careers around one specific musical genre, such as classical or rock, although there are singers with crossover success (singing in more than one genre). Professional singers usually take voice training provided by voice teachers or vocal coaches throughout their careers.\n",
      "\n",
      "Page: Scat singing\n",
      "Summary: Originating in vocal jazz, scat singing or scatting is vocal improvisation with wordless vocables, nonsense syllables or without words at all. In scat singing, the singer improvises melodies and rhythms using the voice solely as an instrument rather than a speaking medium. This is different from vocalese, which uses recognizable lyrics that are sung to pre-existing instrumental solos.\n",
      "\n",
      "Page: Singing hinny\n",
      "Summary: A singing hinny or singin' hinny is a type of bannock, griddle cake or scone, made in the north of England, especially Northumberland and the coal-mining areas of the North East.  In Scotland, they are known as  fatty cutties.\n",
      "Hinny is a term of endearment in the dialects of the Newcastle area.  The singing refers to the sounds of the sizzling of the lard or butter in the rich dough as it is cooked on a hot plate or griddle.\u001b[0m\n",
      "INPUT: {'topic1': 'singing', 'topic2': 'skiing', 'intermediate_steps': [(ToolAgentAction(tool='wikipedia', tool_input='singing', log='\\nInvoking: `wikipedia` with `singing`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_kEP3nT1VuE9jc9RJNO5jxwde', 'function': {'arguments': '{\"__arg1\":\"singing\"}', 'name': 'wikipedia'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-43439c82-b6fa-4440-a9a6-6a94bdff8ef7', tool_calls=[{'name': 'wikipedia', 'args': {'__arg1': 'singing'}, 'id': 'call_kEP3nT1VuE9jc9RJNO5jxwde'}], tool_call_chunks=[{'name': 'wikipedia', 'args': '{\"__arg1\":\"singing\"}', 'id': 'call_kEP3nT1VuE9jc9RJNO5jxwde', 'index': 0}])], tool_call_id='call_kEP3nT1VuE9jc9RJNO5jxwde'), \"Page: Singing\\nSummary: Singing is the act of creating musical sounds with the voice. A person whose profession is singing is called a singer, artist or vocalist (in jazz and/or popular music). Singers perform music (arias, recitatives, songs, etc.) that can be sung with or without accompaniment by musical instruments. Singing is often done in an ensemble of musicians, such as a choir. Singers may perform as soloists or accompanied by anything from a single instrument (as in art songs or some jazz styles) up to a symphony orchestra or big band. Different singing styles include art music such as opera and Chinese opera, Indian music, Greek music, Japanese music, and religious music styles such as gospel, traditional music styles, world music, jazz, blues, ghazal, and popular music styles such as pop, rock, and electronic dance music.\\nSinging can be formal or informal, arranged, or improvised. It may be done as a form of religious devotion, as a hobby, as a source of pleasure, comfort, as part of a ritual, during music education or as a profession. Excellence in singing requires time, dedication, instruction, and regular practice. If practice is done regularly then the sounds can become clearer and stronger. Professional singers usually build their careers around one specific musical genre, such as classical or rock, although there are singers with crossover success (singing in more than one genre). Professional singers usually take voice training provided by voice teachers or vocal coaches throughout their careers.\\n\\nPage: Scat singing\\nSummary: Originating in vocal jazz, scat singing or scatting is vocal improvisation with wordless vocables, nonsense syllables or without words at all. In scat singing, the singer improvises melodies and rhythms using the voice solely as an instrument rather than a speaking medium. This is different from vocalese, which uses recognizable lyrics that are sung to pre-existing instrumental solos.\\n\\nPage: Singing hinny\\nSummary: A singing hinny or singin' hinny is a type of bannock, griddle cake or scone, made in the north of England, especially Northumberland and the coal-mining areas of the North East.  In Scotland, they are known as  fatty cutties.\\nHinny is a term of endearment in the dialects of the Newcastle area.  The singing refers to the sounds of the sizzling of the lard or butter in the rich dough as it is cooked on a hot plate or griddle.\")]}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `skiing`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Skiing\n",
      "Summary: Skiing is the use of skis to glide on snow. Variations of purpose include basic transport, a recreational activity, or a competitive winter sport. Many types of competitive skiing events are recognized by the International Olympic Committee (IOC), and the International Ski and Snowboard Federation (FIS).\n",
      "\n",
      "Page: Alpine skiing\n",
      "Summary: Alpine skiing, or downhill skiing, is the pastime of sliding down snow-covered slopes on skis with fixed-heel bindings, unlike other types of skiing (cross-country, Telemark, or ski jumping), which use skis with free-heel bindings. Whether for recreation or for sport, it is typically practiced at ski resorts, which provide such services as ski lifts, artificial snow making, snow grooming, restaurants, and ski patrol.\n",
      "\"Off-piste\" skiers—those skiing outside ski area boundaries—may employ snowmobiles, helicopters or snowcats to deliver them to the top of a slope. Back-country skiers may use specialized equipment with a free-heel mode, including 'sticky' skins on the bottoms of the skis to stop them sliding backwards during an ascent, then locking the heel and removing the skins for their descent.\n",
      "Alpine ski racing has been held at the Winter Olympics since 1936. A competition corresponding to modern slalom was introduced in Norway at Oslo in 1886.\n",
      "\n",
      "Page: Ski resort\n",
      "Summary: A ski resort is a resort developed for skiing, snowboarding, and other winter sports. In Europe, most ski resorts are towns or villages in or adjacent to a ski area – a mountainous area with pistes (ski trails) and a ski lift system. In North America, it is more common for ski areas to exist well away from towns, so ski resorts usually are destination resorts, often purpose-built and self-contained, where skiing is the main activity.\n",
      "\n",
      "\u001b[0m\n",
      "INPUT: {'topic1': 'singing', 'topic2': 'skiing', 'intermediate_steps': [(ToolAgentAction(tool='wikipedia', tool_input='singing', log='\\nInvoking: `wikipedia` with `singing`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_kEP3nT1VuE9jc9RJNO5jxwde', 'function': {'arguments': '{\"__arg1\":\"singing\"}', 'name': 'wikipedia'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-43439c82-b6fa-4440-a9a6-6a94bdff8ef7', tool_calls=[{'name': 'wikipedia', 'args': {'__arg1': 'singing'}, 'id': 'call_kEP3nT1VuE9jc9RJNO5jxwde'}], tool_call_chunks=[{'name': 'wikipedia', 'args': '{\"__arg1\":\"singing\"}', 'id': 'call_kEP3nT1VuE9jc9RJNO5jxwde', 'index': 0}])], tool_call_id='call_kEP3nT1VuE9jc9RJNO5jxwde'), \"Page: Singing\\nSummary: Singing is the act of creating musical sounds with the voice. A person whose profession is singing is called a singer, artist or vocalist (in jazz and/or popular music). Singers perform music (arias, recitatives, songs, etc.) that can be sung with or without accompaniment by musical instruments. Singing is often done in an ensemble of musicians, such as a choir. Singers may perform as soloists or accompanied by anything from a single instrument (as in art songs or some jazz styles) up to a symphony orchestra or big band. Different singing styles include art music such as opera and Chinese opera, Indian music, Greek music, Japanese music, and religious music styles such as gospel, traditional music styles, world music, jazz, blues, ghazal, and popular music styles such as pop, rock, and electronic dance music.\\nSinging can be formal or informal, arranged, or improvised. It may be done as a form of religious devotion, as a hobby, as a source of pleasure, comfort, as part of a ritual, during music education or as a profession. Excellence in singing requires time, dedication, instruction, and regular practice. If practice is done regularly then the sounds can become clearer and stronger. Professional singers usually build their careers around one specific musical genre, such as classical or rock, although there are singers with crossover success (singing in more than one genre). Professional singers usually take voice training provided by voice teachers or vocal coaches throughout their careers.\\n\\nPage: Scat singing\\nSummary: Originating in vocal jazz, scat singing or scatting is vocal improvisation with wordless vocables, nonsense syllables or without words at all. In scat singing, the singer improvises melodies and rhythms using the voice solely as an instrument rather than a speaking medium. This is different from vocalese, which uses recognizable lyrics that are sung to pre-existing instrumental solos.\\n\\nPage: Singing hinny\\nSummary: A singing hinny or singin' hinny is a type of bannock, griddle cake or scone, made in the north of England, especially Northumberland and the coal-mining areas of the North East.  In Scotland, they are known as  fatty cutties.\\nHinny is a term of endearment in the dialects of the Newcastle area.  The singing refers to the sounds of the sizzling of the lard or butter in the rich dough as it is cooked on a hot plate or griddle.\"), (ToolAgentAction(tool='wikipedia', tool_input='skiing', log='\\nInvoking: `wikipedia` with `skiing`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_6io47aXuJd2H2Up3usTpi4za', 'function': {'arguments': '{\"__arg1\":\"skiing\"}', 'name': 'wikipedia'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-af5e31f2-353b-4e95-ba20-ab2aaf9ebc58', tool_calls=[{'name': 'wikipedia', 'args': {'__arg1': 'skiing'}, 'id': 'call_6io47aXuJd2H2Up3usTpi4za'}], tool_call_chunks=[{'name': 'wikipedia', 'args': '{\"__arg1\":\"skiing\"}', 'id': 'call_6io47aXuJd2H2Up3usTpi4za', 'index': 0}])], tool_call_id='call_6io47aXuJd2H2Up3usTpi4za'), 'Page: Skiing\\nSummary: Skiing is the use of skis to glide on snow. Variations of purpose include basic transport, a recreational activity, or a competitive winter sport. Many types of competitive skiing events are recognized by the International Olympic Committee (IOC), and the International Ski and Snowboard Federation (FIS).\\n\\nPage: Alpine skiing\\nSummary: Alpine skiing, or downhill skiing, is the pastime of sliding down snow-covered slopes on skis with fixed-heel bindings, unlike other types of skiing (cross-country, Telemark, or ski jumping), which use skis with free-heel bindings. Whether for recreation or for sport, it is typically practiced at ski resorts, which provide such services as ski lifts, artificial snow making, snow grooming, restaurants, and ski patrol.\\n\"Off-piste\" skiers—those skiing outside ski area boundaries—may employ snowmobiles, helicopters or snowcats to deliver them to the top of a slope. Back-country skiers may use specialized equipment with a free-heel mode, including \\'sticky\\' skins on the bottoms of the skis to stop them sliding backwards during an ascent, then locking the heel and removing the skins for their descent.\\nAlpine ski racing has been held at the Winter Olympics since 1936. A competition corresponding to modern slalom was introduced in Norway at Oslo in 1886.\\n\\nPage: Ski resort\\nSummary: A ski resort is a resort developed for skiing, snowboarding, and other winter sports. In Europe, most ski resorts are towns or villages in or adjacent to a ski area – a mountainous area with pistes (ski trails) and a ski lift system. In North America, it is more common for ski areas to exist well away from towns, so ski resorts usually are destination resorts, often purpose-built and self-contained, where skiing is the main activity.\\n\\n')]}\n",
      "\u001b[32;1m\u001b[1;3mThe connection between singing and skiing could be through the concept of improvisation. In singing, scat singing involves vocal improvisation with wordless vocables or nonsense syllables, using the voice solely as an instrument. Similarly, in skiing, off-piste skiers may improvise their routes outside ski area boundaries, using specialized equipment like snowmobiles or helicopters to access slopes for a unique skiing experience. Both activities involve creativity, spontaneity, and skill in improvising to create a harmonious and enjoyable performance, whether it's through vocal melodies or navigating challenging ski terrain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topic1': 'singing',\n",
       " 'topic2': 'skiing',\n",
       " 'output': \"The connection between singing and skiing could be through the concept of improvisation. In singing, scat singing involves vocal improvisation with wordless vocables or nonsense syllables, using the voice solely as an instrument. Similarly, in skiing, off-piste skiers may improvise their routes outside ski area boundaries, using specialized equipment like snowmobiles or helicopters to access slopes for a unique skiing experience. Both activities involve creativity, spontaneity, and skill in improvising to create a harmonious and enjoyable performance, whether it's through vocal melodies or navigating challenging ski terrain.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Initialize wikipedia tool, such that the agent has something to do ;) \n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "\n",
    "# Initialize tools to use\n",
    "search = GoogleSearchAPIWrapper()\n",
    "google_search_tool = Tool(\n",
    "    name=\"google-search\",\n",
    "    description=\"Search Google for web results.\",\n",
    "    func=search.run,\n",
    ")\n",
    "\n",
    "\n",
    "# Make sure to bind the tool to the llm, such that the llm can actually use the tool!\n",
    "llm_with_tools = chat_llm.bind_tools([wikipedia_tool])\n",
    "\n",
    "\n",
    "# Initialize the prompt.\n",
    "# For agents, you need to think of how the agent is allowed to 'think'. \n",
    "# Here, this is done by giving the agent access to an 'agent_scratchpad', where it can put all intermediate messages in.\n",
    "wikipedia_topic_link_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"It is your task to make the most random and crazily weird connections between different topics by searching through wikipedia.\"),\n",
    "        (\"user\", \"What is the relation between {topic1} and {topic2}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# A helper function to visualize what the agent is actually doing:\n",
    "def input_print(param):\n",
    "    print(\"\\nINPUT:\", param)\n",
    "    return param\n",
    "\n",
    "# Intialize the agent, by chaining together several parts.\n",
    "agent = (\n",
    "    {   # This first part just formats inputs\n",
    "        # This is primarily important for the agent_scratchpad.\n",
    "        \"topic1\": lambda x: x['topic1'],\n",
    "        \"topic2\": lambda x: x['topic2'],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(x[\"intermediate_steps\"]),\n",
    "        \"print\": lambda x: input_print(x),\n",
    "    }\n",
    "    | wikipedia_topic_link_prompt       # The inputs are fed to the prompt.\n",
    "    | llm_with_tools                    # The formatted prompt is handed down to the LLM, which might, or might not, invoke tools.\n",
    "    | OpenAIToolsAgentOutputParser()    # The output of the llm is formatted by a customer output parser which formats the LLM output such that it can be used as input again for new tools.\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[wikipedia_tool], verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"topic1\": \"singing\", \"topic2\": \"skiing\"})\n",
    "\n",
    "# Looking at the output, the following run is happening:\n",
    "#    Run 1:\n",
    "#       The agent analyzes the initial prompt, and determines it wants to search for 'singing' on wikipedia, and retrieves the content.\n",
    "#       Having the content returned, the parser formats it such that it can be used by the agent again.\n",
    "#    Run 2:\n",
    "#       The agent analyzes the prompt (now containing the first wikipedia search), and determines it wants to search for 'skiing' on wikipedia, and retrieves the content.\n",
    "#       Having the content returned, the parser formats it such that it can be used by the agent again.\n",
    "#    Run 3: \n",
    "#       The agent now has both information on skiing and singing, and determines it can form an answer.\n",
    "#       As such the agent finalizes its output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References!\n",
    "\n",
    "There are some useful links that can help you get further faster. Here is a list:\n",
    "- [On output parser](https://python.langchain.com/docs/modules/model_io/output_parsers/)\n",
    "- [On retrievers](https://python.langchain.com/docs/modules/data_connection/retrievers/)\n",
    "- [On how tools work](https://python.langchain.com/docs/modules/tools/)\n",
    "- [On what type of tools are available](https://python.langchain.com/docs/integrations/tools/)\n",
    "- [On Agents](https://python.langchain.com/docs/modules/agents/)\n",
    "- [On all LLMs which are integrated](https://python.langchain.com/docs/integrations/platforms/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
